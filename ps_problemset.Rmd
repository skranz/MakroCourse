Problemset: ps
Username: Enter Your Username Here








### Frame 
<center>
<h2> Thoughts on Causality, Endogeniety and Instrumental Variable Estimation </h2>

<h3> Sebastian Kranz </h3>
<h3> Uni Ulm</h3>
</center>


## Section Estimating A Demand Function

### Frame Estimating A Demand Function

+ As leading example, we consider the task of estimating a demand function using past observations of prices and quantities (and costs).

+ To simplify thinks, we assume the observed data has been generated by a simple true data generating proceess.


### Frame DGP: Demand Function

+ In period $t$ we have a simple linear demand function of the form:

  $$D_t(p) = a_t - b p$$

  with an intercept $a_t$ given by
  
  $$a_t = a_0 + \varepsilon_t$$
  
+ The slope $b$ and $a_0$ are some fixed numbers which are the same for all periods.

+ $\varepsilon_t$ is a i.i.d. normaly distributed random variable with mean 0. We call $\varepsilon_t$ a demand shock, since it shifts the demand function up or down.


### Frame DGP: Price Setting

+ Assume the observed prices $p_t$ has been set by a clever decision maker who knew, $b$, $a_0$ and the demand shock $\eps_t$ and wanted to maximize the following static profit function:

  $$
  \begin{align*}
  \pi =& D_t(p_t)(p_t-c_t) \\
     =& (a_0 - b p + \varepsilon_t)(p_t-c_t)
  \end{align*}
  $$

  + $c_t$ shall be the constant variable cost of the product that can change between periods.
  
+ Solving the first order condition $\pi'(p_t) = 0$ yields the following price in period $t$:

  $$p_t = \frac{a_0+\varepsilon_t}{2*b} + \frac{c_t}{2}$$
  
  and a resulting output $q_t = D_t(p_t)$ of

  $$q_t = \frac{a_0+\varepsilon_t}{2} - b \frac{c_t}{2}$$


### Frame DGP: Simulation

+ If we specify some concrete numbers for $a_0$, $b$, the standard deviation of $\eps$ and a distribution of costs $c_t$, we can write a short R program that simulates data from this DGP.

```{r "chunk_1",  precompute=TRUE, preknit=TRUE}
set.seed(123456)
a0 = 100 # average intercept of demand function
b = 1 # -b is the slope of the demand function
T = 200 # number of observations
sigma.eps = 5 # standard deviation of demand shock

# Draw T demand shocks
eps = round(rnorm(T,0,sigma.eps),2)

# Draw random costs
c = runif(T, 10, 15)

# Profit maximizing price
p = (a0+eps) / (2*b) + c / 2

# Demand at p
q = (a0+eps) - b * p

# Combine data into a data frame
dat = data.frame(t=1:T,p=p,q=q,c=c)

# Show first 3 rows
head(dat,3)
```
```{r "chunk_2"}
```



### Frame Plot of the simulated data
Here is a plot of the prices vs sold quantity:
```{r "chunk_3",  preknit=TRUE}
library(ggplot2)
ggplot(dat, aes(x=p, y=q)) + 
  geom_point()+
  geom_smooth(method=lm, se=FALSE)
```


### Frame A simple OLS regression
+ The blue line shows the fitted values from a simple linear regression of $q$ on $p$
+ Recall that the average intercept of the demand function is $a_0 = {{a_0}}$ and the slope is $-b = {{-b}}$.
+ An OLS regression of $q$ on $p$ yields estimated coefficients that are completely different:
```{r "chunk_4",  preknit=TRUE}
summary(lm(q~p))
```
+ As you can see from the small standard errors, this difference is **not** due to a small sample estimation error. Even if the number of observations $T$ grows large, the estimated coefficients of the regression line won't converge towards the intercept and slope of the demand function.


### Frame Best Linear Predictor and OLS

+ Given a dependent random variable $y$ and random or deterministic explanatory variables $x=(x_1,...,x_K)$, the predicted value $\hat{y}(\beta | x)$ for a linear predictor $\beta = (\beta0, beta_1, $ is defined by
$$\hat{y}(\beta | x) = \beta_0 + \beta_1 x_1 + ... + \beta_K x_K$$

+ The best linear predictor minimizes the expected squared differences between $y$ and the predicted value $\hat{y(\beta | x)}$, i.e.

  $$\beta^{BLP} = \arg \min_{\beta} E (y-\hat{y}(\beta | x))^2 $$

  + The expectation is taken over the joint distribution of $y$ and all $x$.

+ The OLS estimator is simply defined as the sample analogue to the best linear predictor:

$$\hat{\beta} = \arg \min_{\beta} \sum_{t=1}^T {(y_t-\hat{y}(\beta | x_t))^2} $$
  where here $x_t$ denotes the vector of explanatory variables in period $t$.

+ Under fairly weak conditions, the OLS estimator $\hat{\beta}$ converges in probability to the best linear predictor $\beta^{BLP}$.

```{r "chunk_5", preknit=TRUE, precompute=TRUE}
sim.data = function(T=200, a0=100, b=1, sigma.eps=5, cmin=10, cmax=15) {
  # Draw T demand shocks
  eps = rnorm(T,0,sigma.eps)
  
  # Draw random costs
  c = runif(T, cmin, cmax)
  
  # Profit maximizing price
  p = (a0+eps) / (2*b) + c / 2
  
  # Demand at p
  q = (a0+eps) - b * p
  
  # Combine data into a data frame
  dat = data.frame(t=1:T,p=p,q=q,c=c, eps=eps)
  dat
}
dat = sim.data(T=10000)
summary(lm(q~p, data=dat))
```


### Frame Expected slope
  $$\Delta_p = \frac{\Delta_{\varepsilon} + b \Delta_{c} }{2b}

  $$p_t = \frac{a_0+\varepsilon_t}{2*b} + \frac{c_t}{2}$$
  
  and a resulting output $q_t = D_t(p_t)$ of

  $$q_t = \frac{a_0+\varepsilon_t}{2} - b \frac{c_t}{2}$$





